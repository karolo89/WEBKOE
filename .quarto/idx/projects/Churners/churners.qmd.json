{"title":"Customer Churn Prediction","markdown":{"yaml":{"title":"Customer Churn Prediction","author":"Orozco Karol M.","categories":["Data Journalism","R"],"image":"theranos.jpg"},"headingText":"Setup","containsRefs":false,"markdown":"\n\nThis report presents an analysis of bank customer churn. The dataset contains various attributes of bank customers, and the goal is to predict whether a customer is likely to churn or not.\n\n**Task:** Create a model that predicts churns of bank customers using only 5 features. \n\n```{r setup, include=FALSE}\nlibrary(tidyverse)\nlibrary(caret)\nlibrary(pROC)\nlibrary(MLmetrics)\nlibrary(fastDummies)\nlibrary(skimr)\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)\n```\n\n\n\n```{r}\nbank <-readRDS(gzcon(url(\"https://github.com/karolo89/Raw_Data/raw/main/BankChurners.rds\")))  \nbank = bank %>% rename_all(funs(tolower(.))) \n\n\nskim(bank)\n\nbank = bank %>% mutate(churn = as.factor(churn))\n\nvariables = bank %>% select(-churn) %>% colnames() \n\n\n```\n## PCA on bank data\n\n```{r}\nbank = bank %>% mutate(churn = as.factor(churn))\nbank2 = bank %>% select(-churn) %>% dummy_cols(remove_selected_columns = T)\n\nbank3 = cbind(bank2, select(bank,churn))\n\npr_bank = prcomp(x = select(bank3,-churn), scale = T, center = T)\nsummary(pr_bank)\n\nscreeplot(pr_bank, type = \"lines\")\n\nhead(pr_bank$rotation)\n```\n\n```{r}\nrownames_to_column(as.data.frame(pr_bank$rotation)) %>% \n  select(1:5) %>% \n    filter(abs(PC1) >= 0.3 | abs(PC2) >= 0.3 | abs(PC3) >= 0.3 | abs(PC4) >= 0.3)\n\nprc = bind_cols(select(bank3, churn), as.data.frame(pr_bank$x)) %>%\n  select(1:5) %>%\n    rename(\"rich_men\" = PC1, \"cheap_men\" = PC2, \"young_spenders\" = PC3, \"old_spenders\"= PC4)\n\n#based on the graph below, \"young spenders\" and \"old spenders\" seem to be the most predictive of whether the customer will churn. \n\nprc %>%\npivot_longer(cols = -churn, names_to = \"component\", values_to = \"loading\") %>% mutate(churn = as.factor(churn)) %>%\nggplot(aes(loading, fill=churn)) +\ngeom_density(alpha = 0.5) +\nfacet_grid(.~component)\n\n```\n\n\n## Random Forest model with all variables on entire ds, then  plotting importance of variables to see most impactful: \n\n```{r}\nctrl <- trainControl(method = \"cv\", number = 3, classProbs=TRUE, summaryFunction = twoClassSummary)\n\nbank_index <- createDataPartition(bank$churn, p = 0.80, list = FALSE)\ntrain <- bank[ bank_index, ]\ntest <- bank[-bank_index, ]\n\nbig_model =train(churn ~ .,\n             data = train, \n             method = \"rf\",\n             tunelength = 4,\n             metric = \"ROC\",\n             trControl = ctrl)\n\nimportance = varImp(big_model)\n\nplot(importance)\n\n#most important variables are total_trans_ct, total_trans_amt, total_revolving_bal, total_ct_chng_q4_41, total_relationship_count \n```\n\n## Combining PRC variables with top columns \n\n```{r}\n#choosing \"old_spenders\" and \"young_spenders\" to be 2 of the 5 total features in the model: \nprc2 = prc%>% select(young_spenders,old_spenders) \n\n#combining these features with rest of bank ds, then grabbing best variables: \nbanksy = cbind(prc2, bank3) %>% \n            select(young_spenders, old_spenders,total_trans_ct,total_trans_amt,total_revolving_bal, churn)\n```\n\n## KNN Model \n\n```{r}\n# specify the model to be used (i.e. KNN, Naive Bayes, decision tree, random forest, bagged trees) and the tuning parameters used\n\n\n\nset.seed(504) \n\nbank_index <- createDataPartition(banksy$churn, p = 0.80, list = FALSE)\ntrain <- banksy[ bank_index, ]\ntest <- banksy[-bank_index, ]\n\n# example spec for rf\nfit <- train(churn ~ .,\n             data = train, \n             method = \"knn\",\n             preProcess = c(\"center\",\"scale\"),\n             tuneGrid = expand.grid(k = seq(31,41,2)), # best K between 31 and 41 \n             metric = \"ROC\",\n             trControl = ctrl)\n\nfit\n\nconfusionMatrix(predict(fit, test),factor(test$churn))\n\nmyRoc <- roc(test$churn, predict(fit, test, type=\"prob\")[,2])\n\nplot(myRoc)\nauc(myRoc)\n#.95 AUC \n```\n\n## Downsampling bank data to remove imbalance of yes/no churn: \n\n```{r}\ntraindown = downSample(x = train[,-6], y= train$churn) %>% mutate(churn = Class) %>% select(-Class)\ntraindown %>% group_by(churn) %>% count()\n```\n\n## Random Forest Model with downsampling\n\n```{r}\nfit <- train(churn ~ .,\n             data = traindown, \n             method = \"rf\",\n             tuneLength = 4, \n             metric = \"ROC\",\n             trControl = ctrl)\n\nconfusionMatrix(predict(fit, test),factor(test$churn))\n\nmyRoc <- roc(test$churn, predict(fit, test, type=\"prob\")[,2])\n\nplot(myRoc)\nauc(myRoc) \n# AUC .97\n```\n\n## Gradient boosted model with PCA vs only top 5 variables: \n\n```{r}\n#with PCAs \"young spenders\" and \"old spenders\" \n\nfit_gbm1 <- train(churn ~ .,\n             data = train, \n             method = \"gbm\",\n             tuneLength = 4, \n             preProcess = c(\"center\",\"scale\"),\n             metric = \"ROC\",\n             trControl = ctrl)\n\n\nconfusionMatrix(predict(fit_gbm1, test),factor(test$churn))\n\nmyRoc <- roc(test$churn, predict(fit_gbm1, test, type=\"prob\")[,2])\n\nplot(myRoc)\n## auc(myRoc)\n#kappa = .76, AUC  = .97\n\n\n#with only top 5 variables \n\nbanksy2 = bank %>% select(total_amt_chng_q4_q1, total_trans_ct, total_trans_amt,total_revolving_bal, total_relationship_count,churn)\n\nbank_index2 <- createDataPartition(banksy2$churn, p = 0.80, list = FALSE)\ntrain2 <- banksy2[ bank_index2, ]\ntest2 <- banksy2[-bank_index2, ]\n\nfit_gbm2 <- train(churn ~ .,\n             data = train2, \n             method = \"gbm\",\n             tuneLength = 4, \n             preProcess = c(\"center\",\"scale\"),\n             metric = \"ROC\",\n             trControl = ctrl)\n\nconfusionMatrix(predict(fit_gbm2, test2),factor(test2$churn))\n\nmyRoc <- roc(test2$churn, predict(fit_gbm2, test2, type=\"prob\")[,2])\n\nplot(myRoc)\n## auc(myRoc)\n#kappa = .85, AUC .99\n```\n\nSurprisingly, model with 5 non-PCA features performed better than the addition of 2 PCA features. \n\n```{r}\n# Here are a few lines to inspect your best model. Add some comments about optimal hyperparameters.\nprint(fit_gbm2)\nprint(fit_gbm2$bestTune)\n```\n\n\n## Re-fit and evaluation\n\n```{r}\n# the \"method\" below should match the one you chose above. \n\nset.seed(1504) # I will choose a different seed for evaluation\n\nbank_index <- createDataPartition(banksy2$churn, p = 0.80, list = FALSE)\ntrain <- banksy2[ bank_index, ]\ntest <- banksy2[-bank_index, ]\n\n# example spec for rf\nfit_final <- train(churn ~ .,\n             data = train, \n             method = \"gbm\",\n             tuneGrid=fit_gbm2$bestTune,\n             metric = \"ROC\",\n             trControl = ctrl) \n# The last line means we will fit a model using the best tune parameters your CV found above.\n\nmyRoc <- roc(test$churn, predict(fit_final, test, type=\"prob\")[,2])\n\nplot(myRoc)\n## auc(myRoc)\n\n#Area under the curve: 0.988\n```\n\n\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"churners.html"},"language":{"code-summary":"Behind the Scenes"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.313","editor":"visual","citations-hover":true,"footnotes-hover":true,"theme":{"light":"../../LightTheme.css","dark":"DarkTheme.scss"},"code-copy":true,"title-block-banner":true,"title":"Customer Churn Prediction","author":"Orozco Karol M.","categories":["Data Journalism","R"],"image":"theranos.jpg"},"extensions":{"book":{"multiFile":true}}}}}