<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.313">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Orozco Karol M.">

<title>Karol M. Orozco - Facebook’s Algorithmic Pandora’s Box: Unmasking the Amplification of Fake News and Political Polarization</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<meta property="og:title" content="Karol M. Orozco - Facebook’s Algorithmic Pandora’s Box: Unmasking the Amplification of Fake News and Political Polarization">
<meta property="og:description" content="As we integrate social media into our daily routines, we must consider the potential impact on the spread of information.">
<meta property="og:image" content="fb_icon.jpg">
<meta property="og:site-name" content="Karol M. Orozco">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Karol M. Orozco</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html">
 <span class="menu-text">About Me</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../portfolio.html">
 <span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html">
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../resume.html">
 <span class="menu-text">Professional Summary</span></a>
  </li>  
</ul>
              <div class="quarto-toggle-container">
                  <a href="" class="quarto-color-scheme-toggle nav-link" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
              </div>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Facebook’s Algorithmic Pandora’s Box: Unmasking the Amplification of Fake News and Political Polarization</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">Data Journalism</div>
                <div class="quarto-category">R</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Orozco Karol M. </p>
            </div>
    </div>
      
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>As we integrate social media into our daily routines, we must consider the potential impact on the spread of information. Facebook’s algorithm is intended to personalize users’ News Feeds using engagement, relevance, relationships, post type, and recency, but this approach may unintentionally create filter bubbles that propagate false narratives and reinforce confirmation bias. This article delves into the impact of Facebook’s algorithm on the amplification of incorrect information and political polarization and explores the mechanisms behind this concerning phenomenon.</p>
<section id="understanding-facebooks-algorithm" class="level4">
<h4 class="anchored" data-anchor-id="understanding-facebooks-algorithm">Understanding Facebook’s Algorithm</h4>
<p>Facebook’s algorithm heavily relies on user engagement to determine the popularity and relevance of a post. All forms of engagement, including likes, comments, shares, and reactions, are considered to ensure that the content reaches a broader audience, prompting users to interact with posts of interest and increasing the visibility of similar content in the future. The algorithm aims to deliver content that aligns with users’ interests by analyzing past interactions, preferences, and relationships prioritizing engaging formats such as videos or visually captivating posts in the user’s News Feeds. Moreover, the algorithm considers advertising and promoted content, targeting users based on their demographics, interests, and behaviors to present them with relevant ads.</p>
</section>
<section id="the-evolution-of-the-algorithm" class="level4">
<h4 class="anchored" data-anchor-id="the-evolution-of-the-algorithm">The Evolution of the Algorithm</h4>
<p>Facebook, established by Mark Zuckerberg in 2004 from a Harvard dormitory, quickly gained popularity and became a global sensation with its intuitive design, innovative features, and emphasis on digital connectivity. Throughout its history, Facebook’s algorithm has evolved significantly to meet its user base’s changing needs and challenges. From the introduction of the News Feed in 2006 to the ongoing refinements, the algorithm has aimed to balance personalization, user engagement, and responsible content curation. However, the platform has faced ethical and societal challenges, including privacy and transparency concerns, data security issues, and misinformation.</p>
<p>The News Feed’s introduction replaced users’ need to browse friends’ profiles manually. This infinite scroll of content tailored to each user’s interests and connections revolutionized how people consumed information on the platform. The algorithm gained further power in 2009 with the introduction of the Like button, allowing users to express approval or support for posts and photos.</p>
<p>In 2011, Facebook shifted its algorithm to prioritize content based on user engagement metrics like likes, comments, and shares. This update aimed to deliver more relevant and engaging content to users, enhancing their overall experience on the platform. By leveraging these metrics, the algorithm became a powerful tool for advertisers to target their desired audience precisely.</p>
<p>The algorithm continued to evolve in 2013 with the introduction of Graph Search. This feature enabled users to search for specific content, posts, photos, and people based on their connections and interests. This update improved the search experience and further personalized content recommendations, making it easier for users to discover relevant information.</p>
<p>In 2015, Facebook announced an algorithm update that prioritized posts from friends and family over content from brands, publishers, and pages. With growing concerns about the spread of clickbait headlines and fake news, Facebook took action to reduce the visibility of fake news, updating the system to favor posts from trustworthy sources and promoting more accurate and reliable information. This move aimed to address challenges associated with misinformation and enhance the platform’s content quality.</p>
<p>In 2018, the company made significant changes to de-emphasize posts created by publishers and brands and prioritize content shared by friends and families. In 2019, the company introduced the “Why am I seeing this post?” feature, allowing users to understand the factors influencing their News Feed content and promoting transparency. Users gained more control over the types of content they see through improved customization options, empowering them to tailor their Facebook experience.</p>
<p>In 2020, the algorithm was adjusted to combat false information dissemination, especially during significant events like elections. The platform prioritized authoritative sources, implemented measures to prevent the amplification of misinformation, and worked with third-party fact-checkers to minimize the impact on elections and provide users with reliable and more accurate information.</p>
</section>
<section id="spread-of-misinformation-and-political-polarization-on-facebook" class="level4">
<h4 class="anchored" data-anchor-id="spread-of-misinformation-and-political-polarization-on-facebook">Spread of Misinformation and Political Polarization on Facebook</h4>
<p>The prevalence of fake news on Facebook is a significant concern encompassing a wide range of problematic content, including imposter news, conspiracy theories, hyperpartisan websites, and “junk news.” The insidious use of clickbait to attract readers and the dissemination of dubious information through bots and trolls, known as “computational propaganda,” only exacerbates the issue. This problem extends beyond news, surrounding cultural commentary and satire, and raises crucial questions about how user engagement and algorithmic prioritization contribute to the spread of misinformation.</p>
<p>The influence of user engagement on Facebook’s dissemination of fake news cannot be disregarded. Those who unintentionally like, comment, or share false information only increase their visibility and reach. Facebook’s algorithm can magnify fake news with high engagement, making it visible to a broader audience. Additionally, personalized content based on user preferences and behavior can create echo chambers and filter bubbles, exposing users to misinformation that aligns with their beliefs and interests. Acknowledging that maximizing engagement can lead to polarization is crucial, particularly within networks of like-minded users.</p>
<p>While Facebook has tried to combat the spread of fake news, the issue remains complex. The platform has partnered with third-party organizations for fact-checking, flagging disputed content, and reducing false information’s visibility. However, balancing freedom of expression, user engagement, and the responsibility to combat misinformation is an ongoing challenge.</p>
<p>Regarding political polarization, experts challenge Facebook CEO Mark Zuckerberg’s denial that the platform fuels divisiveness. Zuckerberg’s assertions have been disputed despite testifying before a U.S. House of Representatives subcommittee in March 2021 and attributing division to external factors, such as the political and media environment. Facebook’s VP for global affairs and communication, Nick Clegg, has similarly claimed there is no evidence to support the notion that social media is a clear driver of polarization. However, the scholarly consensus is that social media platforms like Facebook and Twitter intensify political sectarianism, contrary to the company’s claims. In articles published in Science in October 2020 and Trends in Cognitive Sciences in August 2021, researchers have concluded that social media is a significant facilitator of polarization.</p>
<p>Facebook’s algorithm limits exposure to cross-cutting links, causing users to connect with others who share the same political beliefs and reducing the likelihood of encountering diverse opinions. While this algorithm aims to enhance user experience, it inadvertently reduces politically diverse content by around 5% for conservatives and 8% for liberals. Typically, individuals have five politically like-minded friends on Facebook for every friend from the opposing side.</p>
<p>![](politic.jpg){style=“display: block; margin: 0 auto;”}</p>
<p>Although Silicon Valley is not solely responsible for these issues, a study conducted in March 2020 showed that taking a break from Facebook for a month significantly reduced polarization of views on policy issues among participants. The study published by the American Economic Review suggested that exposure to political content on social media tends to provoke heightened emotions, anger toward the opposing side, and more robust views on specific issues, which contradicts Facebook’s narrative.</p>
</section>
<section id="algorithmic-failures-high-costs" class="level4">
<h4 class="anchored" data-anchor-id="algorithmic-failures-high-costs">Algorithmic Failure’s High Costs</h4>
<p>The spread of false information through social media is a grave issue that can trigger severe short, and long-lasting consequences for individuals, society, and organizations. Acknowledging that misinformation can lead to social division, offer misleading medical advice, and promote fraudulent schemes that erode trust and pose serious health risks is paramount. The fact that fake news purporting that pure alcohol (methanol) could cure COVID-19 led to approximately 800 deaths in Iran, with an additional 5,876 people hospitalized due to methanol poisoning, is unacceptable. This tragic example underscores the precarious nature of misinformation for individuals and society.</p>
<p>Moreover, the Cambridge Analytica and Facebook case explicitly demonstrates the cost of false information for businesses. Cambridge Analytica was accused of manipulating political outcomes through Facebook data, with some executives proposing unethical practices such as bribery and fake news. These actions ultimately led to the closure of the company in 2018 and Facebook paying a record $5 billion settlement to the Federal Trade Commission (FTC) and another $100 million to settle allegations of misuse of user data with the U.S. Securities and Exchange Commission.</p>
<p>Such actions have far-reaching consequences beyond these companies, as non-profit organizations and advocacy groups may struggle to communicate their messages effectively when fake news dominates the conversation. This effect in non-profits was demonstrated in 2014 when anti-abortion activists secretly recorded meetings and staff lunches at Planned Parenthood, a non-profit organization that provides reproductive healthcare options. The activists then edited and disseminated the footage through social media, creating a viral sensation. The hashtag #defundPP was shared over 1.3 million times within a few months, subjecting Planned Parenthood to intense scrutiny and calls for defunding.</p>
<p>Another example of the algorithm failure cost is the aftermath of the January 6th attack on the U.S. Capitol, which has been financially and politically disastrous. It’s been widely reported that Facebook groups played a significant role in fueling political polarization and spreading false narratives that contributed to the siege. These groups saw a massive surge in posts aimed at undermining the legitimacy of Joe Biden’s victory, totaling over 650,000 between Election Day and the attack. The costs of the damage caused by this event have already exceeded $30 million and are expected to continue rising. These expenses include implementing enhanced security measures, repairing damaged infrastructure, and deploying additional law enforcement resources. However, the financial implications are only a tiny part of the more significant problem. The attack on the Capitol represents a severe assault on American democratic principles and substantially threatens the peaceful transfer of power.</p>
</section>
<section id="data-ethics-and-facebooks-responsibility" class="level4">
<h4 class="anchored" data-anchor-id="data-ethics-and-facebooks-responsibility">Data Ethics and Facebook’s Responsibility</h4>
<p>Facebook’s handling of user data has sparked significant concerns, mainly due to the infamous Cambridge Analytica scandal in 2018. The scandal highlighted Facebook’s unethical practices, including weak consent mechanisms, inadequate data protection, user profiling, targeted advertising, and a lack of transparency. The scandal revealed that personal data from around 87 million Facebook users had been collected and exploited through a third-party app called “This Is Your Digital Life.” This breach violated users’ privacy rights and exposed their data to misuse. Cambridge Analytica used this unauthorized data to create psychographic profiles and targeted political advertising during the 2016 U.S. presidential election and other campaigns worldwide.</p>
<p>As of today, misleading, and extremist content disguised as journalism and facts continue to dominate the most shared posts on the platform, making Facebook a prominent source of misinformation. Likewise, this criticism is further accentuated by the legal and regulatory landscape, allowing the company to prioritize profit maximization and shareholder value over proactive ethical considerations.</p>
<p>Regarding algorithm responsibility, Article 230 of the Communications Decency Act of 1996 is a significant factor. Originally intended to safeguard freedom of expression online, this legislation has shielded platforms like Facebook from active duty in regulating their hosted content. However, it has been exploited by social media startups and big tech companies, enabling harmful content to thrive. The article stipulates that interactive computer service providers or users should not be held accountable for the information provided by content creators.</p>
<p>Facebook promotes a “shared responsibility” approach and emphasizes community cooperation. The company argues that it cannot be the sole arbiter of truth and instead believes in empowering individuals to have a voice. They encourage users to report false posts, avoid sharing or posting misleading articles, and flag spammy content, placing some responsibility on the user community.</p>
<p>In the face of these concerns, it is evident that Facebook needs to address its data ethics practices more effectively and take substantial steps to combat misinformation while prioritizing transparency, user privacy, and responsible decision-making.</p>
</section>
<section id="next-steps-collaborative-solutions-section-230-reform-proactive-measures-by-social-media-companies-and-digital-citizenship" class="level4">
<h4 class="anchored" data-anchor-id="next-steps-collaborative-solutions-section-230-reform-proactive-measures-by-social-media-companies-and-digital-citizenship">Next Steps: Collaborative Solutions, Section 230 Reform, Proactive Measures by Social Media Companies, and Digital Citizenship</h4>
<p>Several next steps are crucial to address the challenges in the online environment: Section 230 Reform: Reforming Section 230 of the Communications Decency Act of 1996 is necessary to encourage platforms to exercise their duty of care responsibly without unnecessary regulatory burdens. This reform could motivate media outlets to address potential risks proactively and create a safer and more responsible online environment. The protections outlined in Section 230 were crafted over 25 years ago, a time of limited technological capabilities and naive technological optimism. In light of the significant changes since then, these protections are outdated and need reconsideration and updating by the legislators.</p>
<p>Collaboration for Comprehensive Solutions: Governments, tech companies, civil society organizations, and individuals must join forces to develop comprehensive solutions. Collaborative efforts can include sharing expertise, resources, and best practices to effectively address the spread of fake news. This collective approach ensures a more holistic and impactful response.</p>
<p>Strengthening Media Literacy and Promoting Digital Citizenship: Investing in media literacy programs is crucial to empower individuals with the critical skills to navigate the digital landscape. Education initiatives should focus on fostering media literacy, promoting digital citizenship, and cultivating necessary thinking skills. By equipping people with the tools to discern reliable information from misinformation, they become active participants in combating the spread of fake news.</p>
<p>Long-term Algorithmic Adjustments: Social media companies, such as Facebook, must acknowledge their contribution to political polarization and take proactive measures to reduce the prevalence of divisive content. Making lasting changes to their algorithms is a practical step in curbing heated debates and reducing the amplification of polarizing narratives. Continuously refining automated systems and moderation policies is necessary to balance fostering free expression and mitigating the unintended suppression of legitimate political discourse.</p>
<p>Embrace transparency: Social media platforms must prioritize transparency by disclosing how their algorithms work, such as how content is rated, suggested, and removed. In addition, these platforms should continuously enhance their data protection measures, participate in independent audits, and foster a responsible environment for sharing information.</p>
</section>
<section id="conclusion" class="level4">
<h4 class="anchored" data-anchor-id="conclusion">Conclusion</h4>
<p>The potential contribution of Facebook’s algorithm to spreading fake news and political polarization is a significant concern. Despite its original purpose to personalize users’ News Feeds, the algorithm could create filter bubbles reinforcing false narratives and confirmation bias. Imposter news, conspiracy theories, hyperpartisan websites, and “junk news” are just a few examples of inappropriate content in the fake news sphere on Facebook. It’s worth noting that user engagement is a significant factor in disseminating phony information, and personalized content based on user preferences and behavior can create echo chambers and filter bubbles that expose users to misinformation that aligns with their beliefs and interests.</p>
<p>It’s essential to recognize that maximizing engagement can lead to polarization, particularly within networks of like-minded users. Facebook has tried to counter the spread of fake news, but balancing freedom of expression, user engagement, and the responsibility to combat misinformation is challenging. To develop comprehensive solutions, we must collaborate, promote media literacy, adjust algorithms, and embrace transparency.</p>
</section>
<section id="references" class="level4">
<h4 class="anchored" data-anchor-id="references">References</h4>
<p>Allcott, H., Braghieri, L., Eichmeyer, S., &amp; Gentzkow, M. (2020). [The Welfare Effects of Social Media](https://doi.org/10.1257/aer.20190468). American Economic Review, 110(3), 629-676.</p>
<p>Barrett, P., et al.&nbsp;(2021, September 27). [How Tech Platforms Fuel U.S. Political Polarization and What Government Can Do about It](https://www.brookings.edu/blog/techtank/2021/09/27/how-tech-platforms-fuel-u-s-political-polarization-and-what-government-can-do-about-it/). Brookings.</p>
<p>Bleiberg, J., &amp; West, D. M. (2015, May 13). [Political Polarization on Facebook](https://www.brookings.edu/blog/techtank/2015/05/13/political-polarization-on-facebook/). Brookings.</p>
<p>Cochrane, E., &amp; Broadwater, L. (2021, February 24). [Capitol Riot Costs Will Exceed $30 Million, Official Tells Congress](https://www.nytimes.com/2021/02/24/us/politics/capitol-riot-damage.html). The New York Times.</p>
<p>Department of Justice. (2020, June 3). [Department of Justice’s Review of Section 230 of the Communications Decency Act of 1996](https://www.justice.gov/archives/ag/department-justice-s-review-section-230-communications-decency-act-1996).</p>
<p>Finkel, E. J., et al.&nbsp;(2020). [Political Sectarianism in America](https://doi.org/10.1126/science.abe1715). Science, 370(6516), 533-536.</p>
<p>Harvard Kennedy School. (n.d.). [Research Note: The Scale of Facebook’s Problem Depends upon How ‘Fake News’ Is Classified](https://misinforeview.hks.harvard.edu/article/research-note-the-scale-of-facebooks-problem-depends-upon-how-fake-news-is-classified/).</p>
<p>Harvard Law Today. (n.d.). [The Algorithm Has Primacy over Media … over Each of Us, and It Controls What We Do](https://hls.harvard.edu/today/the-algorithm-has-primacy-over-media-over-each-of-us-and-it-controls-what-we-do/).</p>
<p>Madrigal, A. C. (2017, October 12). [What Facebook Did to American Democracy](https://www.theatlantic.com/technology/archive/2017/10/what-facebook-did/542502/). The Atlantic.</p>
<p>MIT Technology Review. (2021, March 11). [How Facebook Got Addicted to Spreading Misinformation](https://www.technologyreview.com/2021/03/11/1020600/facebook-responsible-ai-misinformation/).</p>
<p>MIT Technology Review. (2021, November 20). [How Facebook and Google Fund Global Misinformation](https://www.technologyreview.com/2021/11/20/1039076/facebook-google-disinformation-clickbait/).</p>
<p>Mosseri, A. (2017, April 7). [Working to Stop Misinformation and False News](https://www.facebook.com/formedia/blog/working-to-stop-misinformation-and-false-news). Facebook Media.</p>
<p>Rocha, Y. M., et al.&nbsp;(2021). [The Impact of Fake News on Social Media and Its Influence on Health during the COVID-19 Pandemic: A Systematic Review](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8502082/). Journal of Public Health, 1(10).</p>
<p>Silverman, C. (2016, November 16). [This Analysis Shows How Viral Fake Election News Stories Outperformed Real News on Facebook](https://www.buzzfeednews.com/article/craigsilverman/viral-fake-election-news-outperformed-real-news-on-facebook). BuzzFeed News.</p>
<p>Smith, M. D., &amp; Van Alstyne, M. (2021, August 12). [It’s Time to Update Section 230](https://hbr.org/2021/08/its-time-to-update-section-230). Harvard Business Review.</p>
<p>Stars, S., Stortstrom, R., Lagrace, L., &amp; King, N. (2018). [Overview of Fake News: For Non-Profit Organizations](https://stars.library.ucf.edu/cgi/viewcontent.cgi?article=1001&amp;context=publicsectormedialiteracy).</p>
<p>The Guardian. (2016, November 10). [Facebook’s Failure: Did Fake News and Polarized Politics Get Trump Elected?](https://www.theguardian.com/technology/2016/nov/10/facebook-fake-news-election-conspiracy-theories).</p>
<p>The New York Times. (2015, May 8). [Facebook Use Polarizing? Site Begs to Differ](https://www.nytimes.com/2015/05/08/technology/facebook-study-disputes-theory-of-political-polarization-among-users.html).</p>
<p>The New York Times. (2020, May 28). [Facebook and Its Secret Policies](https://www.nytimes.com/2020/05/28/technology/facebook-polarization.html).</p>
<p>Van Bavel, J. J., et al.&nbsp;(2021). [How Social Media Shapes Polarization](https://doi.org/10.1016/j.tics.2021.07.013). Trends in Cognitive Sciences, 25(11).</p>
<p>Facebook AI. (n.d.). [How We’re Using Fairness Flow to Help Build AI That Works Better for Everyone](https://ai.facebook.com/blog/how-were-using-fairness-flow-to-help-build-ai-that-works-better-for-everyone).</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://www.quarto.org">Made with quarto®</a>
  </li>  
</ul>
    </div>   
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/karolorozcoe/">
      <i class="bi bi-linkedin" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/karolo89">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="mailto:karol.marianoe@gmail.com">
      <i class="bi bi-envelope-fill" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>



</body></html>