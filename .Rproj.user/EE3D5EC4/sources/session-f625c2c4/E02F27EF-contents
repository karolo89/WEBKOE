---
title: "Unveiling TriMet's Brand Perception: A Sentiment Analysis Journey through Twitter"
author: "Orozco Karol M."
image: transit.jpg
date: "4-20-2023"
format:
  html:
    toc: true
    toc-location: right
    html-math-method: katex
    page-layout: full
execute: 
  warning: false
  message: false
categories: [R, Sentiment Analysis, Brand]
---

## Introduction:

## Approach and Methodology

#### Load the required packages and data

```{r, warning=FALSE, message=FALSE}

library(hms)
library(lubridate) 
library(tidytext)
library(tm)
library(wordcloud)
library(igraph)
library(glue)
library(networkD3)
library(rtweet)
library(plyr)
library(stringr)
library(ggplot2)
library(ggeasy)
library(plotly)
library(dplyr)  
library(hms)
library(lubridate) 
library(magrittr)
library(tidyverse)
library(janeaustenr)
library(widyr)
library(readxl)
library(httr)

```


```{r, include=FALSE}

# Download the Excel file from GitHub without using cache
url <- "https://github.com/karolo89/WEBKOE/raw/main/BrandPerception/%40TriMet_followers.xlsx"
temp_file <- tempfile()  # Create a temporary file
download.file(url, destfile = temp_file, mode = "wb", cacheOK = FALSE)  # Download the file

# Read the Excel file
tweets <- read_excel(temp_file)

```

```{r}
head(tweets)
```

```{r}
#create a function to do all the data clean process
result_list <- llply(dfList, function(x) {
                #only keep tweets using English as the main language
                x<-subset(x,x$`19: Language`== "English") 
                #change the variable name for future convenience
                x$tweet=x$`2: Tweet` 
                #drop all other variables except tweet
                x<-x[,22] 
                #create a new variable to track the number of tweet
                x$tweetnumber<-1:length(x$tweet) 
                #return the cleaner dataframe with 2 variables
                return(x) 
                })
```


```{r}
tweets.txt <- sapply(tweets, function(t)t$getText())
# Ignore graphical Parameters to avoid input errors
tweets.txt <- str_replace_all(tweets.txt,"[^[:graph:]]", " ")

## pre-processing text:
clean.text = function(x)
{
  # convert to lower case
  x = tolower(x)
  # remove rt
  x = gsub("rt", "", x)
  # remove at
  x = gsub("@\\w+", "", x)
  # remove punctuation
  x = gsub("[[:punct:]]", "", x)
  # remove numbers
  x = gsub("[[:digit:]]", "", x)
  # remove links http
  x = gsub("http\\w+", "", x)
  # remove tabs
  x = gsub("[ |\t]{2,}", "", x)
  # remove blank spaces at the beginning
  x = gsub("^ ", "", x)
  # remove blank spaces at the end
  x = gsub(" $", "", x)
  # some other cleaning text
  x = gsub('https://','',x)
  x = gsub('http://','',x)
  x = gsub('[^[:graph:]]', ' ',x)
  x = gsub('[[:punct:]]', '', x)
  x = gsub('[[:cntrl:]]', '', x)
  x = gsub('\\d+', '', x)
  x = str_replace_all(x,"[^[:graph:]]", " ")
  return(x)
}

cleanText <- clean.text(tweets.txt)
# remove empty results (if any)
idx <- which(cleanText == " ")
cleanText <- cleanText[cleanText != " "]
```

