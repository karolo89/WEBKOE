{
  "hash": "05c3e9e5f4ea66b4b549444a13872421",
  "result": {
    "markdown": "---\ntitle: \"The Sky's the Limit: Unveiling the Untold Stories of US Airline Woes on Twitter!\"\nauthor: \"Orozco Karol M.\"\nimage: transit.jpg\ndate: \"4-20-2023\"\nformat:\n  html:\n    toc: true\n    toc-location: right\n    html-math-method: katex\n    page-layout: full\nexecute: \n  warning: false\n  message: false\ncategories: [R, Sentiment Analysis, Brand]\n---\n\n\n## Introduction\n\nWelcome to this sentiment analysis project in R, where I delve into the realm of major U.S. airlines and uncover the sentiments expressed by Twitter users regarding their experiences. By analyzing data scraped from February 2015, I aim to gain insights into the problems faced by these airlines through the eyes of their customers.\n\nThe dataset used in this analysis originated from Crowdflower's Data for Everyone library. It is available in both CSV file and SQLite database formats, providing flexibility for your preferred data exploration methods. The transformation code used to format the data can be found on GitHub, ensuring transparency and reproducibility.\n\nWithin this dataset, you will find a comprehensive collection of tweets categorized based on their sentiment: positive, negative, or neutral. Additionally, negative tweets have been further classified based on the reasons provided, ranging from \"late flight\" to \"rude service.\" This granular categorization enables us to pinpoint specific problem areas faced by these airlines.\n\nJoin me on this journey as we uncover the untold stories behind each major U.S. airline, unraveling the sentiments expressed by Twitter users and shedding light on the challenges faced by the industry.\n\n## Approach and Methodology\n\n#### Load the required packages and data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(hms)\nlibrary(twitteR)\nlibrary(lubridate) \nlibrary(tidytext)\nlibrary(tm)\nlibrary(wordcloud)\nlibrary(igraph)\nlibrary(glue)\nlibrary(networkD3)\nlibrary(rtweet)\nlibrary(plyr)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(ggeasy)\nlibrary(plotly)\nlibrary(dplyr)  \nlibrary(hms)\nlibrary(lubridate) \nlibrary(magrittr)\nlibrary(tidyverse)\nlibrary(janeaustenr)\nlibrary(widyr)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntweets <- read.csv(\"https://raw.githubusercontent.com/karolo89/WEBKOE/main/SatisfactionAnalysis/Tweets.csv\")%>%\n  select(-negativereason_confidence)\n\nhead(tweets)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     tweet_id airline_sentiment airline_sentiment_confidence negativereason\n1 5.70306e+17           neutral                       1.0000               \n2 5.70301e+17          positive                       0.3486               \n3 5.70301e+17           neutral                       0.6837               \n4 5.70301e+17          negative                       1.0000     Bad Flight\n5 5.70301e+17          negative                       1.0000     Can't Tell\n6 5.70301e+17          negative                       1.0000     Can't Tell\n         airline airline_sentiment_gold       name negativereason_gold\n1 Virgin America                           cairdin                    \n2 Virgin America                          jnardino                    \n3 Virgin America                        yvonnalynn                    \n4 Virgin America                          jnardino                    \n5 Virgin America                          jnardino                    \n6 Virgin America                          jnardino                    \n  retweet_count\n1             0\n2             0\n3             0\n4             0\n5             0\n6             0\n                                                                                                                                      text\n1                                                                                                      @VirginAmerica What @dhepburn said.\n2                                                                 @VirginAmerica plus you've added commercials to the experience... tacky.\n3                                                                  @VirginAmerica I didn't today... Must mean I need to take another trip!\n4           @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse\n5                                                                                  @VirginAmerica and it's a really big bad thing about it\n6 @VirginAmerica seriously would pay $30 a flight for seats that didn't have this playing.\\nit's really the only bad thing about flying VA\n  tweet_coord   tweet_created tweet_location              user_timezone\n1             2/24/2015 11:35                Eastern Time (US & Canada)\n2             2/24/2015 11:15                Pacific Time (US & Canada)\n3             2/24/2015 11:15      Lets Play Central Time (US & Canada)\n4             2/24/2015 11:15                Pacific Time (US & Canada)\n5             2/24/2015 11:14                Pacific Time (US & Canada)\n6             2/24/2015 11:14                Pacific Time (US & Canada)\n```\n:::\n:::\n\n\n## Extracting Tweets\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# extracting 4000 tweets related to global warming topic\nn.tweet <- length(tweets)\n\n# convert tweets to a data frame\ntweets.df <- as.data.frame(tweets)\n\ntweets.txt <- tweets$getText\n\n# Ignore graphical Parameters to avoid input errors\ntweets.txt <- str_replace_all(tweets.txt,\"[^[:graph:]]\", \" \")\n\n## pre-processing text:\nclean.text = function(x)\n{\n  # convert to lower case\n  x = tolower(x)\n  # remove rt\n  x = gsub(\"rt\", \"\", x)\n  # remove at\n  x = gsub(\"@\\\\w+\", \"\", x)\n  # remove punctuation\n  x = gsub(\"[[:punct:]]\", \"\", x)\n  # remove numbers\n  x = gsub(\"[[:digit:]]\", \"\", x)\n  # remove links http\n  x = gsub(\"http\\\\w+\", \"\", x)\n  # remove tabs\n  x = gsub(\"[ |\\t]{2,}\", \"\", x)\n  # remove blank spaces at the beginning\n  x = gsub(\"^ \", \"\", x)\n  # remove blank spaces at the end\n  x = gsub(\" $\", \"\", x)\n  # some other cleaning text\n  x = gsub('https://','',x)\n  x = gsub('http://','',x)\n  x = gsub('[^[:graph:]]', ' ',x)\n  x = gsub('[[:punct:]]', '', x)\n  x = gsub('[[:cntrl:]]', '', x)\n  x = gsub('\\\\d+', '', x)\n  x = str_replace_all(x,\"[^[:graph:]]\", \" \")\n  return(x)\n}\n\ncleanText <- clean.text(tweets.txt)\n# remove empty results (if any)\nidx <- which(cleanText == \" \")\ncleanText <- cleanText[cleanText != \" \"]\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(tweets.df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    tweet_id         airline_sentiment  airline_sentiment_confidence\n Min.   :5.676e+17   Length:14640       Min.   :0.3350              \n 1st Qu.:5.686e+17   Class :character   1st Qu.:0.6923              \n Median :5.695e+17   Mode  :character   Median :1.0000              \n Mean   :5.692e+17                      Mean   :0.9002              \n 3rd Qu.:5.699e+17                      3rd Qu.:1.0000              \n Max.   :5.703e+17                      Max.   :1.0000              \n negativereason       airline          airline_sentiment_gold\n Length:14640       Length:14640       Length:14640          \n Class :character   Class :character   Class :character      \n Mode  :character   Mode  :character   Mode  :character      \n                                                             \n                                                             \n                                                             \n     name           negativereason_gold retweet_count          text          \n Length:14640       Length:14640        Min.   : 0.00000   Length:14640      \n Class :character   Class :character    1st Qu.: 0.00000   Class :character  \n Mode  :character   Mode  :character    Median : 0.00000   Mode  :character  \n                                        Mean   : 0.08265                     \n                                        3rd Qu.: 0.00000                     \n                                        Max.   :44.00000                     \n tweet_coord        tweet_created      tweet_location     user_timezone     \n Length:14640       Length:14640       Length:14640       Length:14640      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Apply the mutate function to update 'created' column\ntweets.df <- tweets.df %>% \n  mutate(\n    created = tweet_created %>% \n      # Remove zeros.\n      str_remove_all(pattern = '\\\\+0000') %>%\n      # Parse date.\n      parse_date_time(orders = '%m/%d/%Y %H:%M')\n  )\n\n# Create a new column 'Created_At_Round' by rounding 'created' to hours\ntweets.df <- tweets.df %>% \n  mutate(Created_At_Round = round_date(created, unit = \"hours\") %>% as.POSIXct())\n\n# Extract the minimum value of 'created' column\nmin_created <- min(tweets.df$created)\n\n# Print the minimum value\nprint(min_created)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"2015-02-16 23:36:00 UTC\"\n```\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}