"0","score.sentiment = function(sentences, pos.words, neg.words, airline, .progress='none')"
"0","{"
"0","  require(plyr)"
"0","  require(stringr)"
"0","  "
"0","  # we are giving vector of sentences as input. "
"0","  # plyr will handle a list or a vector as an ""l"" for us"
"0","  # we want a simple array of scores back, so we use ""l"" + ""a"" + ""ply"" = laply:"
"0","  scores = laply(sentences, function(sentence, pos.words, neg.words) {"
"0","    "
"0","    # clean up sentences with R's regex-driven global substitute, gsub() function:"
"0","    sentence = gsub('https://','',sentence)"
"0","    sentence = gsub('http://','',sentence)"
"0","    sentence = gsub('[^[:graph:]]', ' ',sentence)"
"0","    sentence = gsub('[[:punct:]]', '', sentence)"
"0","    sentence = gsub('[[:cntrl:]]', '', sentence)"
"0","    sentence = gsub('\\d+', '', sentence)"
"0","    sentence = str_replace_all(sentence,""[^[:graph:]]"", "" "")"
"0","    # and convert to lower case:"
"0","    sentence = tolower(sentence)"
"0","    "
"0","    # split into words. str_split is in the stringr package"
"0","    word.list = str_split(sentence, '\\s+')"
"0","    # sometimes a list() is one level of hierarchy too much"
"0","    words = unlist(word.list)"
"0","    "
"0","    # compare our words to the dictionaries of positive & negative terms"
"0","    pos.matches = match(words, pos.words)"
"0","    neg.matches = match(words, neg.words)"
"0","    "
"0","    # match() returns the position of the matched term or NA"
"0","    # we just want a TRUE/FALSE:"
"0","    pos.matches = !is.na(pos.matches)"
"0","    neg.matches = !is.na(neg.matches)"
"0","    "
"0","    # TRUE/FALSE will be treated as 1/0 by sum():"
"0","    score = sum(pos.matches) - sum(neg.matches)"
"0","    "
"0","    return(score)"
"0","  }, pos.words, neg.words, .progress=.progress )"
"0","  "
"0","  scores.df = data.frame(score=scores, text=sentences)"
"0","  return(scores.df)"
"0","}"
