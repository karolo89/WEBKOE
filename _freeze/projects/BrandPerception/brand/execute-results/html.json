{
  "hash": "5ed6284eb0c7ea04738c4898c781dfb9",
  "result": {
    "markdown": "---\ntitle: \"The Sky's the Limit: Unveiling the Untold Stories of US Airline Woes on Twitter!\"\nauthor: \"Orozco Karol M.\"\nimage: airplane.jpg\ndate: \"4-20-2023\"\nformat:\n  html:\n    toc: true\n    toc-location: right\n    html-math-method: katex\n    page-layout: full\nexecute: \n  warning: false\n  message: false\ncategories: [R, Sentiment Analysis, Brand]\n---\n\n\n## Introduction\n\nWelcome to this sentiment analysis project in R, where I delve into the realm of major U.S. airlines and uncover the sentiments expressed by Twitter users regarding their experiences. By analyzing data scraped from February 2015, I aim to gain insights into the problems faced by these airlines through the eyes of their customers.\n\nThe dataset used in this analysis originated from Crowdflower's Data for Everyone library. It is available in both CSV file and SQLite database formats, providing flexibility for your preferred data exploration methods. The transformation code used to format the data can be found on GitHub, ensuring transparency and reproducibility.\n\nWithin this dataset, you will find a comprehensive collection of tweets categorized based on their sentiment: positive, negative, or neutral. Additionally, negative tweets have been further classified based on the reasons provided, ranging from \"late flight\" to \"rude service.\" This granular categorization enables us to pinpoint specific problem areas faced by these airlines.\n\nJoin me on this journey as we uncover the untold stories behind each major U.S. airline, unraveling the sentiments expressed by Twitter users and shedding light on the challenges faced by the industry.\n\n## Approach and Methodology\n\nThe first step is to gather relevant Twitter data. This typically involves utilizing the Twitter API or third-party tools to retrieve tweets based on specific keywords, hashtags, or user profiles. The collected data forms the basis for further analysis.\n\nOnce the data is collected, it undergoes preprocessing to clean and prepare it for sentiment analysis. This involves removing irrelevant information such as URLs, usernames, and special characters, as well as standardizing the text by converting it to lowercase and removing stopwords.\n\n#### Load the required packages and data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(hms)\nlibrary(twitteR)\nlibrary(lubridate) \nlibrary(tidytext)\nlibrary(tm)\nlibrary(wordcloud)\nlibrary(igraph)\nlibrary(glue)\nlibrary(networkD3)\nlibrary(rtweet)\nlibrary(plyr)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(ggeasy)\nlibrary(plotly)\nlibrary(dplyr)  \nlibrary(hms)\nlibrary(lubridate) \nlibrary(magrittr)\nlibrary(tidyverse)\nlibrary(janeaustenr)\nlibrary(widyr)\nlibrary(RColorBrewer)\nlibrary(ggeasy)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntweets <- read.csv(\"https://raw.githubusercontent.com/karolo89/WEBKOE/main/SatisfactionAnalysis/Tweets.csv\")%>%\n  select(-negativereason_confidence)\n\nhead(tweets)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     tweet_id airline_sentiment airline_sentiment_confidence negativereason\n1 5.70306e+17           neutral                       1.0000               \n2 5.70301e+17          positive                       0.3486               \n3 5.70301e+17           neutral                       0.6837               \n4 5.70301e+17          negative                       1.0000     Bad Flight\n5 5.70301e+17          negative                       1.0000     Can't Tell\n6 5.70301e+17          negative                       1.0000     Can't Tell\n         airline airline_sentiment_gold       name negativereason_gold\n1 Virgin America                           cairdin                    \n2 Virgin America                          jnardino                    \n3 Virgin America                        yvonnalynn                    \n4 Virgin America                          jnardino                    \n5 Virgin America                          jnardino                    \n6 Virgin America                          jnardino                    \n  retweet_count\n1             0\n2             0\n3             0\n4             0\n5             0\n6             0\n                                                                                                                                      text\n1                                                                                                      @VirginAmerica What @dhepburn said.\n2                                                                 @VirginAmerica plus you've added commercials to the experience... tacky.\n3                                                                  @VirginAmerica I didn't today... Must mean I need to take another trip!\n4           @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse\n5                                                                                  @VirginAmerica and it's a really big bad thing about it\n6 @VirginAmerica seriously would pay $30 a flight for seats that didn't have this playing.\\nit's really the only bad thing about flying VA\n  tweet_coord   tweet_created tweet_location              user_timezone\n1             2/24/2015 11:35                Eastern Time (US & Canada)\n2             2/24/2015 11:15                Pacific Time (US & Canada)\n3             2/24/2015 11:15      Lets Play Central Time (US & Canada)\n4             2/24/2015 11:15                Pacific Time (US & Canada)\n5             2/24/2015 11:14                Pacific Time (US & Canada)\n6             2/24/2015 11:14                Pacific Time (US & Canada)\n```\n:::\n\n```{.r .cell-code}\nstr(tweets)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'data.frame':\t14640 obs. of  14 variables:\n $ tweet_id                    : num  5.7e+17 5.7e+17 5.7e+17 5.7e+17 5.7e+17 ...\n $ airline_sentiment           : chr  \"neutral\" \"positive\" \"neutral\" \"negative\" ...\n $ airline_sentiment_confidence: num  1 0.349 0.684 1 1 ...\n $ negativereason              : chr  \"\" \"\" \"\" \"Bad Flight\" ...\n $ airline                     : chr  \"Virgin America\" \"Virgin America\" \"Virgin America\" \"Virgin America\" ...\n $ airline_sentiment_gold      : chr  \"\" \"\" \"\" \"\" ...\n $ name                        : chr  \"cairdin\" \"jnardino\" \"yvonnalynn\" \"jnardino\" ...\n $ negativereason_gold         : chr  \"\" \"\" \"\" \"\" ...\n $ retweet_count               : int  0 0 0 0 0 0 0 0 0 0 ...\n $ text                        : chr  \"@VirginAmerica What @dhepburn said.\" \"@VirginAmerica plus you've added commercials to the experience... tacky.\" \"@VirginAmerica I didn't today... Must mean I need to take another trip!\" \"@VirginAmerica it's really aggressive to blast obnoxious \\\"entertainment\\\" in your guests' faces &amp; they hav\"| __truncated__ ...\n $ tweet_coord                 : chr  \"\" \"\" \"\" \"\" ...\n $ tweet_created               : chr  \"2/24/2015 11:35\" \"2/24/2015 11:15\" \"2/24/2015 11:15\" \"2/24/2015 11:15\" ...\n $ tweet_location              : chr  \"\" \"\" \"Lets Play\" \"\" ...\n $ user_timezone               : chr  \"Eastern Time (US & Canada)\" \"Pacific Time (US & Canada)\" \"Central Time (US & Canada)\" \"Pacific Time (US & Canada)\" ...\n```\n:::\n:::\n\n\n## Data Analysis\n\n### Data Overview\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(ggthemes)\nlibrary(dplyr)\n\ntweets <- tweets %>%\n  mutate(airline = factor(airline, levels = names(sort(table(airline), decreasing = TRUE))))\n\nggplot(tweets) +\n  aes(airline, fill = airline) +\n  geom_bar() +\n  geom_text(stat = 'count', aes(label = paste0(round((..count..)/sum(..count..) * 100), \"%\")),   vjust = 1.6, color = \"white\") +\n  labs(title = 'Number of Tweets by Airlines', x = \"\", y = \"\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 16),\n    axis.title = element_text(size = 12),\n    axis.text = element_text(size = 10),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.border = element_blank(),\n    panel.background = element_blank(),\n    legend.position = \"none\",\n    legend.title = element_blank(),\n    legend.text = element_text(size = 10),\n    axis.text.y = element_text(size = 10),\n    legend.key.size = unit(0.5, \"cm\"),\n    legend.key.height = unit(0.5, \"cm\"),\n    legend.key.width = unit(0.5, \"cm\")\n  ) +\n  scale_fill_tableau()\n```\n\n::: {.cell-output-display}\n![](brand_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntableau_colors <- c(\"#4E79A7\", \"#F28E2B\", \"#E15759\", \"#76B7B2\", \"#59A14F\", \"#EDC948\")\n\ntweets %>%\n  group_by(airline, airline_sentiment) %>%\n  summarise(count = n()) %>%\n  ggplot(aes(airline, count, fill = airline)) +\n  geom_bar(stat = \"identity\") +\n  facet_wrap(~ airline_sentiment, ncol = 1) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 9)) +\n  labs(x = \"Airlines\", y = \"Count of Tweet Sentiments\") +\n  theme_minimal() +\n  theme(\n    axis.title = element_text(size = 12),\n    axis.text = element_text(size = 10),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.border = element_blank(),\n    panel.background = element_blank(),\n    legend.position = \"none\",\n    legend.title = element_blank(),\n    legend.text = element_text(size = 10),\n    axis.text.y = element_text(size = 10),\n    legend.key.size = unit(0.5, \"cm\"),\n    legend.key.height = unit(0.5, \"cm\"),\n    legend.key.width = unit(0.5, \"cm\")\n  ) +\n  scale_fill_manual(values = tableau_colors)\n```\n\n::: {.cell-output-display}\n![](brand_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntweets %>%\n  group_by(negativereason) %>%\n  summarise(count = n(), na.rm = TRUE) %>%\n  arrange(desc(count)) %>%\n  ggplot(aes(reorder(negativereason, count), count)) +\n  geom_bar(fill = \"#4E79A7\", color = \"black\", stat = \"identity\") +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1, size = 9),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.border = element_blank(),\n    panel.background = element_blank(),\n    legend.position = \"none\",\n    plot.title = element_text(hjust = 0.5, size = 16),\n    axis.title = element_text(size = 12),\n    axis.text = element_text(size = 10)\n  ) +\n  labs(x = \"\", y = \"Count of Negative Reasons\") +\n  scale_fill_manual(values = c(\"#4E79A7\"))  # Using Tableau palette color\n```\n\n::: {.cell-output-display}\n![](brand_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n\n### Extracting Tweets\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntweets.df <- tweets %>%\n  mutate(text = str_replace_all(text, \"[^[:graph:]]\", \" \") %>%\n           gsub(\"https://\", \"\", .) %>% \n           gsub(\"rt\", \"\", .) %>%\n           gsub(\"@\\\\w+\", \"\", .) %>%\n           gsub(\"http://\", \"\", .) %>%\n           gsub(\"[[:digit:]]\", \"\", .) %>%\n           gsub(\"[[:punct:]]\", \"\", .) %>%\n           gsub(\"[ |\\t]{2,}\", \"\", .) %>%\n           gsub(\"[^[:graph:]]\", \" \", .) %>%\n           gsub(\"[[:punct:]]\", \"\", .) %>%\n           gsub(\"[[:cntrl:]]\", \"\", .) %>%\n           gsub(\" $\", \"\", .) %>%\n           gsub(\"\\\\d+\", \"\", .) %>%\n           str_replace_all(., \"[^[:graph:]]\", \" \") %>%\n           tolower())\n\ncleanText <- tweets.df$text\n# remove empty results (if any)\ncleanText <- cleanText[cleanText != \" \"]\n\nhead(tweets.df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     tweet_id airline_sentiment airline_sentiment_confidence negativereason\n1 5.70306e+17           neutral                       1.0000               \n2 5.70301e+17          positive                       0.3486               \n3 5.70301e+17           neutral                       0.6837               \n4 5.70301e+17          negative                       1.0000     Bad Flight\n5 5.70301e+17          negative                       1.0000     Can't Tell\n6 5.70301e+17          negative                       1.0000     Can't Tell\n         airline airline_sentiment_gold       name negativereason_gold\n1 Virgin America                           cairdin                    \n2 Virgin America                          jnardino                    \n3 Virgin America                        yvonnalynn                    \n4 Virgin America                          jnardino                    \n5 Virgin America                          jnardino                    \n6 Virgin America                          jnardino                    \n  retweet_count\n1             0\n2             0\n3             0\n4             0\n5             0\n6             0\n                                                                                                               text\n1                                                                                                          whatsaid\n2                                                              plus youve added commercials to the experience tacky\n3                                                               i didnt today must mean i need to take another trip\n4           its really aggressive to blast obnoxious enteainment in your guests faces amp they have little recourse\n5                                                                           and its a really big bad thing about it\n6  seriously would paya flight for seats that didnt have this playing its really the only bad thing about flying va\n  tweet_coord   tweet_created tweet_location              user_timezone\n1             2/24/2015 11:35                Eastern Time (US & Canada)\n2             2/24/2015 11:15                Pacific Time (US & Canada)\n3             2/24/2015 11:15      Lets Play Central Time (US & Canada)\n4             2/24/2015 11:15                Pacific Time (US & Canada)\n5             2/24/2015 11:14                Pacific Time (US & Canada)\n6             2/24/2015 11:14                Pacific Time (US & Canada)\n```\n:::\n:::\n\n\n### Frequency of Tweets\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Apply the mutate function to update 'created' column\ntweets.df <- tweets.df %>% \n  mutate(\n    created = tweet_created %>% \n      # Remove zeros.\n      str_remove_all(pattern = '\\\\+0000') %>%\n      # Parse date.\n      parse_date_time(orders = '%m/%d/%Y %H:%M')\n  )\n\n# Create a new column 'Created_At_Round' by rounding 'created' to hours\ntweets.df <- tweets.df %>% \n  mutate(Created_At_Round = round_date(created, unit = \"hours\") %>% as.POSIXct())\n\n# Extract the minimum value of 'created' column\nmin_created <- min(tweets.df$created)\n\n# Print the minimum value\nprint(min_created)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"2015-02-16 23:36:00 UTC\"\n```\n:::\n\n```{.r .cell-code}\ntweets.df %>% pull(created) %>% max()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"2015-02-24 11:53:00 UTC\"\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplt <- tweets.df %>% \n  dplyr::count(Created_At_Round) %>% \n  ggplot(mapping = aes(x = Created_At_Round, y = n)) +\n  geom_line(color = \"blue\") +\n  labs(x = \"Date\", y = \"Number of Tweets\", title = \"Number of Tweets per Hour\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))\n\nggplotly(plt)\n```\n\n::: {.cell-output-display}\n```{=html}\n<div class=\"plotly html-widget html-fill-item-overflow-hidden html-fill-item\" id=\"htmlwidget-9012db2430dd758a5508\" style=\"width:100%;height:464px;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-9012db2430dd758a5508\">{\"x\":{\"data\":[{\"x\":[1424131200,1424134800,1424138400,1424142000,1424145600,1424149200,1424152800,1424156400,1424160000,1424163600,1424167200,1424170800,1424174400,1424178000,1424181600,1424185200,1424188800,1424192400,1424196000,1424199600,1424203200,1424206800,1424210400,1424214000,1424217600,1424221200,1424224800,1424228400,1424232000,1424235600,1424239200,1424242800,1424246400,1424250000,1424253600,1424257200,1424260800,1424264400,1424268000,1424271600,1424275200,1424278800,1424282400,1424286000,1424289600,1424293200,1424296800,1424300400,1424304000,1424307600,1424311200,1424314800,1424318400,1424322000,1424325600,1424329200,1424332800,1424336400,1424340000,1424343600,1424347200,1424350800,1424354400,1424358000,1424361600,1424365200,1424368800,1424372400,1424376000,1424379600,1424383200,1424386800,1424390400,1424394000,1424397600,1424401200,1424404800,1424408400,1424412000,1424415600,1424419200,1424422800,1424426400,1424430000,1424433600,1424437200,1424440800,1424444400,1424448000,1424451600,1424455200,1424458800,1424462400,1424466000,1424469600,1424473200,1424476800,1424480400,1424484000,1424487600,1424491200,1424494800,1424498400,1424502000,1424505600,1424509200,1424512800,1424516400,1424520000,1424523600,1424527200,1424530800,1424534400,1424538000,1424541600,1424545200,1424548800,1424552400,1424556000,1424559600,1424563200,1424566800,1424570400,1424574000,1424577600,1424581200,1424584800,1424588400,1424592000,1424595600,1424599200,1424602800,1424606400,1424610000,1424613600,1424617200,1424620800,1424624400,1424628000,1424631600,1424635200,1424638800,1424642400,1424646000,1424649600,1424653200,1424656800,1424660400,1424664000,1424667600,1424671200,1424674800,1424678400,1424682000,1424685600,1424689200,1424692800,1424696400,1424700000,1424703600,1424707200,1424710800,1424714400,1424718000,1424721600,1424725200,1424728800,1424732400,1424736000,1424739600,1424743200,1424746800,1424750400,1424754000,1424757600,1424761200,1424764800,1424768400,1424772000,1424775600,1424779200],\"y\":[7,1,5,2,1,7,8,8,31,154,111,120,117,93,145,96,81,92,93,75,64,47,31,15,12,16,13,15,25,43,53,85,79,89,95,68,79,79,92,85,81,89,56,71,49,42,21,15,2,6,15,15,36,35,35,73,118,86,81,95,74,54,74,80,74,70,61,83,68,62,44,22,14,11,12,13,17,52,65,87,123,91,106,94,70,100,88,77,90,59,83,86,53,52,42,25,7,5,19,22,25,41,31,64,72,64,67,86,100,113,130,86,62,83,98,91,100,88,65,34,14,26,24,21,39,69,93,96,135,106,105,102,143,236,245,223,229,255,248,204,152,136,81,81,46,34,37,43,65,116,131,161,185,170,214,232,207,210,175,169,133,90,120,120,119,125,81,53,30,25,22,56,77,84,110,114,141,207,219,199,75],\"text\":[\"Created_At_Round: 2015-02-17 00:00:00<br />n:   7\",\"Created_At_Round: 2015-02-17 01:00:00<br />n:   1\",\"Created_At_Round: 2015-02-17 02:00:00<br />n:   5\",\"Created_At_Round: 2015-02-17 03:00:00<br />n:   2\",\"Created_At_Round: 2015-02-17 04:00:00<br />n:   1\",\"Created_At_Round: 2015-02-17 05:00:00<br />n:   7\",\"Created_At_Round: 2015-02-17 06:00:00<br />n:   8\",\"Created_At_Round: 2015-02-17 07:00:00<br />n:   8\",\"Created_At_Round: 2015-02-17 08:00:00<br />n:  31\",\"Created_At_Round: 2015-02-17 09:00:00<br />n: 154\",\"Created_At_Round: 2015-02-17 10:00:00<br />n: 111\",\"Created_At_Round: 2015-02-17 11:00:00<br />n: 120\",\"Created_At_Round: 2015-02-17 12:00:00<br />n: 117\",\"Created_At_Round: 2015-02-17 13:00:00<br />n:  93\",\"Created_At_Round: 2015-02-17 14:00:00<br />n: 145\",\"Created_At_Round: 2015-02-17 15:00:00<br />n:  96\",\"Created_At_Round: 2015-02-17 16:00:00<br />n:  81\",\"Created_At_Round: 2015-02-17 17:00:00<br />n:  92\",\"Created_At_Round: 2015-02-17 18:00:00<br />n:  93\",\"Created_At_Round: 2015-02-17 19:00:00<br />n:  75\",\"Created_At_Round: 2015-02-17 20:00:00<br />n:  64\",\"Created_At_Round: 2015-02-17 21:00:00<br />n:  47\",\"Created_At_Round: 2015-02-17 22:00:00<br />n:  31\",\"Created_At_Round: 2015-02-17 23:00:00<br />n:  15\",\"Created_At_Round: 2015-02-18 00:00:00<br />n:  12\",\"Created_At_Round: 2015-02-18 01:00:00<br />n:  16\",\"Created_At_Round: 2015-02-18 02:00:00<br />n:  13\",\"Created_At_Round: 2015-02-18 03:00:00<br />n:  15\",\"Created_At_Round: 2015-02-18 04:00:00<br />n:  25\",\"Created_At_Round: 2015-02-18 05:00:00<br />n:  43\",\"Created_At_Round: 2015-02-18 06:00:00<br />n:  53\",\"Created_At_Round: 2015-02-18 07:00:00<br />n:  85\",\"Created_At_Round: 2015-02-18 08:00:00<br />n:  79\",\"Created_At_Round: 2015-02-18 09:00:00<br />n:  89\",\"Created_At_Round: 2015-02-18 10:00:00<br />n:  95\",\"Created_At_Round: 2015-02-18 11:00:00<br />n:  68\",\"Created_At_Round: 2015-02-18 12:00:00<br />n:  79\",\"Created_At_Round: 2015-02-18 13:00:00<br />n:  79\",\"Created_At_Round: 2015-02-18 14:00:00<br />n:  92\",\"Created_At_Round: 2015-02-18 15:00:00<br />n:  85\",\"Created_At_Round: 2015-02-18 16:00:00<br />n:  81\",\"Created_At_Round: 2015-02-18 17:00:00<br />n:  89\",\"Created_At_Round: 2015-02-18 18:00:00<br />n:  56\",\"Created_At_Round: 2015-02-18 19:00:00<br />n:  71\",\"Created_At_Round: 2015-02-18 20:00:00<br />n:  49\",\"Created_At_Round: 2015-02-18 21:00:00<br />n:  42\",\"Created_At_Round: 2015-02-18 22:00:00<br />n:  21\",\"Created_At_Round: 2015-02-18 23:00:00<br />n:  15\",\"Created_At_Round: 2015-02-19 00:00:00<br />n:   2\",\"Created_At_Round: 2015-02-19 01:00:00<br />n:   6\",\"Created_At_Round: 2015-02-19 02:00:00<br />n:  15\",\"Created_At_Round: 2015-02-19 03:00:00<br />n:  15\",\"Created_At_Round: 2015-02-19 04:00:00<br />n:  36\",\"Created_At_Round: 2015-02-19 05:00:00<br />n:  35\",\"Created_At_Round: 2015-02-19 06:00:00<br />n:  35\",\"Created_At_Round: 2015-02-19 07:00:00<br />n:  73\",\"Created_At_Round: 2015-02-19 08:00:00<br />n: 118\",\"Created_At_Round: 2015-02-19 09:00:00<br />n:  86\",\"Created_At_Round: 2015-02-19 10:00:00<br />n:  81\",\"Created_At_Round: 2015-02-19 11:00:00<br />n:  95\",\"Created_At_Round: 2015-02-19 12:00:00<br />n:  74\",\"Created_At_Round: 2015-02-19 13:00:00<br />n:  54\",\"Created_At_Round: 2015-02-19 14:00:00<br />n:  74\",\"Created_At_Round: 2015-02-19 15:00:00<br />n:  80\",\"Created_At_Round: 2015-02-19 16:00:00<br />n:  74\",\"Created_At_Round: 2015-02-19 17:00:00<br />n:  70\",\"Created_At_Round: 2015-02-19 18:00:00<br />n:  61\",\"Created_At_Round: 2015-02-19 19:00:00<br />n:  83\",\"Created_At_Round: 2015-02-19 20:00:00<br />n:  68\",\"Created_At_Round: 2015-02-19 21:00:00<br />n:  62\",\"Created_At_Round: 2015-02-19 22:00:00<br />n:  44\",\"Created_At_Round: 2015-02-19 23:00:00<br />n:  22\",\"Created_At_Round: 2015-02-20 00:00:00<br />n:  14\",\"Created_At_Round: 2015-02-20 01:00:00<br />n:  11\",\"Created_At_Round: 2015-02-20 02:00:00<br />n:  12\",\"Created_At_Round: 2015-02-20 03:00:00<br />n:  13\",\"Created_At_Round: 2015-02-20 04:00:00<br />n:  17\",\"Created_At_Round: 2015-02-20 05:00:00<br />n:  52\",\"Created_At_Round: 2015-02-20 06:00:00<br />n:  65\",\"Created_At_Round: 2015-02-20 07:00:00<br />n:  87\",\"Created_At_Round: 2015-02-20 08:00:00<br />n: 123\",\"Created_At_Round: 2015-02-20 09:00:00<br />n:  91\",\"Created_At_Round: 2015-02-20 10:00:00<br />n: 106\",\"Created_At_Round: 2015-02-20 11:00:00<br />n:  94\",\"Created_At_Round: 2015-02-20 12:00:00<br />n:  70\",\"Created_At_Round: 2015-02-20 13:00:00<br />n: 100\",\"Created_At_Round: 2015-02-20 14:00:00<br />n:  88\",\"Created_At_Round: 2015-02-20 15:00:00<br />n:  77\",\"Created_At_Round: 2015-02-20 16:00:00<br />n:  90\",\"Created_At_Round: 2015-02-20 17:00:00<br />n:  59\",\"Created_At_Round: 2015-02-20 18:00:00<br />n:  83\",\"Created_At_Round: 2015-02-20 19:00:00<br />n:  86\",\"Created_At_Round: 2015-02-20 20:00:00<br />n:  53\",\"Created_At_Round: 2015-02-20 21:00:00<br />n:  52\",\"Created_At_Round: 2015-02-20 22:00:00<br />n:  42\",\"Created_At_Round: 2015-02-20 23:00:00<br />n:  25\",\"Created_At_Round: 2015-02-21 00:00:00<br />n:   7\",\"Created_At_Round: 2015-02-21 01:00:00<br />n:   5\",\"Created_At_Round: 2015-02-21 02:00:00<br />n:  19\",\"Created_At_Round: 2015-02-21 03:00:00<br />n:  22\",\"Created_At_Round: 2015-02-21 04:00:00<br />n:  25\",\"Created_At_Round: 2015-02-21 05:00:00<br />n:  41\",\"Created_At_Round: 2015-02-21 06:00:00<br />n:  31\",\"Created_At_Round: 2015-02-21 07:00:00<br />n:  64\",\"Created_At_Round: 2015-02-21 08:00:00<br />n:  72\",\"Created_At_Round: 2015-02-21 09:00:00<br />n:  64\",\"Created_At_Round: 2015-02-21 10:00:00<br />n:  67\",\"Created_At_Round: 2015-02-21 11:00:00<br />n:  86\",\"Created_At_Round: 2015-02-21 12:00:00<br />n: 100\",\"Created_At_Round: 2015-02-21 13:00:00<br />n: 113\",\"Created_At_Round: 2015-02-21 14:00:00<br />n: 130\",\"Created_At_Round: 2015-02-21 15:00:00<br />n:  86\",\"Created_At_Round: 2015-02-21 16:00:00<br />n:  62\",\"Created_At_Round: 2015-02-21 17:00:00<br />n:  83\",\"Created_At_Round: 2015-02-21 18:00:00<br />n:  98\",\"Created_At_Round: 2015-02-21 19:00:00<br />n:  91\",\"Created_At_Round: 2015-02-21 20:00:00<br />n: 100\",\"Created_At_Round: 2015-02-21 21:00:00<br />n:  88\",\"Created_At_Round: 2015-02-21 22:00:00<br />n:  65\",\"Created_At_Round: 2015-02-21 23:00:00<br />n:  34\",\"Created_At_Round: 2015-02-22 00:00:00<br />n:  14\",\"Created_At_Round: 2015-02-22 01:00:00<br />n:  26\",\"Created_At_Round: 2015-02-22 02:00:00<br />n:  24\",\"Created_At_Round: 2015-02-22 03:00:00<br />n:  21\",\"Created_At_Round: 2015-02-22 04:00:00<br />n:  39\",\"Created_At_Round: 2015-02-22 05:00:00<br />n:  69\",\"Created_At_Round: 2015-02-22 06:00:00<br />n:  93\",\"Created_At_Round: 2015-02-22 07:00:00<br />n:  96\",\"Created_At_Round: 2015-02-22 08:00:00<br />n: 135\",\"Created_At_Round: 2015-02-22 09:00:00<br />n: 106\",\"Created_At_Round: 2015-02-22 10:00:00<br />n: 105\",\"Created_At_Round: 2015-02-22 11:00:00<br />n: 102\",\"Created_At_Round: 2015-02-22 12:00:00<br />n: 143\",\"Created_At_Round: 2015-02-22 13:00:00<br />n: 236\",\"Created_At_Round: 2015-02-22 14:00:00<br />n: 245\",\"Created_At_Round: 2015-02-22 15:00:00<br />n: 223\",\"Created_At_Round: 2015-02-22 16:00:00<br />n: 229\",\"Created_At_Round: 2015-02-22 17:00:00<br />n: 255\",\"Created_At_Round: 2015-02-22 18:00:00<br />n: 248\",\"Created_At_Round: 2015-02-22 19:00:00<br />n: 204\",\"Created_At_Round: 2015-02-22 20:00:00<br />n: 152\",\"Created_At_Round: 2015-02-22 21:00:00<br />n: 136\",\"Created_At_Round: 2015-02-22 22:00:00<br />n:  81\",\"Created_At_Round: 2015-02-22 23:00:00<br />n:  81\",\"Created_At_Round: 2015-02-23 00:00:00<br />n:  46\",\"Created_At_Round: 2015-02-23 01:00:00<br />n:  34\",\"Created_At_Round: 2015-02-23 02:00:00<br />n:  37\",\"Created_At_Round: 2015-02-23 03:00:00<br />n:  43\",\"Created_At_Round: 2015-02-23 04:00:00<br />n:  65\",\"Created_At_Round: 2015-02-23 05:00:00<br />n: 116\",\"Created_At_Round: 2015-02-23 06:00:00<br />n: 131\",\"Created_At_Round: 2015-02-23 07:00:00<br />n: 161\",\"Created_At_Round: 2015-02-23 08:00:00<br />n: 185\",\"Created_At_Round: 2015-02-23 09:00:00<br />n: 170\",\"Created_At_Round: 2015-02-23 10:00:00<br />n: 214\",\"Created_At_Round: 2015-02-23 11:00:00<br />n: 232\",\"Created_At_Round: 2015-02-23 12:00:00<br />n: 207\",\"Created_At_Round: 2015-02-23 13:00:00<br />n: 210\",\"Created_At_Round: 2015-02-23 14:00:00<br />n: 175\",\"Created_At_Round: 2015-02-23 15:00:00<br />n: 169\",\"Created_At_Round: 2015-02-23 16:00:00<br />n: 133\",\"Created_At_Round: 2015-02-23 17:00:00<br />n:  90\",\"Created_At_Round: 2015-02-23 18:00:00<br />n: 120\",\"Created_At_Round: 2015-02-23 19:00:00<br />n: 120\",\"Created_At_Round: 2015-02-23 20:00:00<br />n: 119\",\"Created_At_Round: 2015-02-23 21:00:00<br />n: 125\",\"Created_At_Round: 2015-02-23 22:00:00<br />n:  81\",\"Created_At_Round: 2015-02-23 23:00:00<br />n:  53\",\"Created_At_Round: 2015-02-24 00:00:00<br />n:  30\",\"Created_At_Round: 2015-02-24 01:00:00<br />n:  25\",\"Created_At_Round: 2015-02-24 02:00:00<br />n:  22\",\"Created_At_Round: 2015-02-24 03:00:00<br />n:  56\",\"Created_At_Round: 2015-02-24 04:00:00<br />n:  77\",\"Created_At_Round: 2015-02-24 05:00:00<br />n:  84\",\"Created_At_Round: 2015-02-24 06:00:00<br />n: 110\",\"Created_At_Round: 2015-02-24 07:00:00<br />n: 114\",\"Created_At_Round: 2015-02-24 08:00:00<br />n: 141\",\"Created_At_Round: 2015-02-24 09:00:00<br />n: 207\",\"Created_At_Round: 2015-02-24 10:00:00<br />n: 219\",\"Created_At_Round: 2015-02-24 11:00:00<br />n: 199\",\"Created_At_Round: 2015-02-24 12:00:00<br />n:  75\"],\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(0,0,255,1)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null}],\"layout\":{\"margin\":{\"t\":43.7625570776256,\"r\":7.30593607305936,\"b\":40.1826484018265,\"l\":43.1050228310502},\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187},\"title\":{\"text\":\"Number of Tweets per Hour\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":17.5342465753425},\"x\":0.5,\"xref\":\"paper\"},\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[1424098800,1424811600],\"tickmode\":\"array\",\"ticktext\":[\"Feb 18\",\"Feb 20\",\"Feb 22\",\"Feb 24\"],\"tickvals\":[1424217600,1424390400,1424563200,1424736000],\"categoryorder\":\"array\",\"categoryarray\":[\"Feb 18\",\"Feb 20\",\"Feb 22\",\"Feb 24\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(235,235,235,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"y\",\"title\":{\"text\":\"Date\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[-11.7,267.7],\"tickmode\":\"array\",\"ticktext\":[\"0\",\"100\",\"200\"],\"tickvals\":[0,100,200],\"categoryorder\":\"array\",\"categoryarray\":[\"0\",\"100\",\"200\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(235,235,235,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"x\",\"title\":{\"text\":\"Number of Tweets\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"shapes\":[{\"type\":\"rect\",\"fillcolor\":null,\"line\":{\"color\":null,\"width\":0,\"linetype\":[]},\"yref\":\"paper\",\"xref\":\"paper\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false,\"legend\":{\"bgcolor\":null,\"bordercolor\":null,\"borderwidth\":0,\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":11.689497716895}},\"hovermode\":\"closest\",\"barmode\":\"relative\"},\"config\":{\"doubleClick\":\"reset\",\"modeBarButtonsToAdd\":[\"hoverclosest\",\"hovercompare\"],\"showSendToCloud\":false},\"source\":\"A\",\"attrs\":{\"40d4409e5ba0\":{\"x\":{},\"y\":{},\"type\":\"scatter\"}},\"cur_data\":\"40d4409e5ba0\",\"visdat\":{\"40d4409e5ba0\":[\"function (y) \",\"x\"]},\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}</script>\n```\n:::\n:::\n\n\n### Loading sentiment word lists\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidytext)\n\n# Extract the positive and negative word lists\nwords <- get_sentiments(\"bing\")\n\npositive <- words %>% filter(sentiment == \"positive\")\nnegative <- words %>% filter(sentiment == \"negative\")\n\npos.words <- c(positive$word, 'upgrade', 'Congrats', 'prizes', 'prize', 'thanks', 'thnx', 'Grt', 'gr8', 'plz', 'trending', 'recovering', 'brainstorm', 'leader')\nneg.words <- c(negative$word, 'wtf', 'wait', 'waiting', 'epicfail', 'Fight', 'fighting', 'arrest', 'no', 'not')\n```\n:::\n\n\n### Sentiment scoring function\n\n\n::: {.cell}\n\n```{.r .cell-code}\nscore.sentiment = function(sentences, pos.words, neg.words, airline, .progress='none')\n{\n  require(plyr)\n  require(stringr)\n  \n  # we are giving vector of sentences as input. \n  # plyr will handle a list or a vector as an \"l\" for us\n  # we want a simple array of scores back, so we use \"l\" + \"a\" + \"ply\" = laply:\n  scores = laply(sentences, function(sentence, pos.words, neg.words) {\n    \n    # clean up sentences with R's regex-driven global substitute, gsub() function:\n    sentence = gsub('https://','',sentence)\n    sentence = gsub('http://','',sentence)\n    sentence = gsub('[^[:graph:]]', ' ',sentence)\n    sentence = gsub('[[:punct:]]', '', sentence)\n    sentence = gsub('[[:cntrl:]]', '', sentence)\n    sentence = gsub('\\\\d+', '', sentence)\n    sentence = str_replace_all(sentence,\"[^[:graph:]]\", \" \")\n    # and convert to lower case:\n    sentence = tolower(sentence)\n    \n    # split into words. str_split is in the stringr package\n    word.list = str_split(sentence, '\\\\s+')\n    # sometimes a list() is one level of hierarchy too much\n    words = unlist(word.list)\n    \n    # compare our words to the dictionaries of positive & negative terms\n    pos.matches = match(words, pos.words)\n    neg.matches = match(words, neg.words)\n    \n    # match() returns the position of the matched term or NA\n    # we just want a TRUE/FALSE:\n    pos.matches = !is.na(pos.matches)\n    neg.matches = !is.na(neg.matches)\n    \n    # TRUE/FALSE will be treated as 1/0 by sum():\n    score = sum(pos.matches) - sum(neg.matches)\n    \n    return(score)\n  }, pos.words, neg.words, .progress=.progress )\n  \n  scores.df = data.frame(score=scores, text=sentences)\n  return(scores.df)\n}\n```\n:::\n\n\n### Calculating the sentiment score\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanalysis <- score.sentiment(cleanText, pos.words, neg.words)\n# Sentiment score frequency table\nscore_table <- as.data.frame(table(analysis$score))\ncolnames(score_table) <- c(\"Sentiment Score\", \"Frequency\")\n\nscore_table\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Sentiment Score Frequency\n1               -8         1\n2               -7         1\n3               -6         6\n4               -5        28\n5               -4       142\n6               -3       503\n7               -2      1442\n8               -1      3358\n9                0      5507\n10               1      2540\n11               2       870\n12               3       179\n13               4        50\n14               5        11\n15               6         2\n```\n:::\n:::\n\n\n### Histogram of sentiment scores\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanalysis %>%\n  ggplot(aes(x = score)) +\n geom_histogram(binwidth = 1, fill = \"#2171b5\") +\n  labs(x = \"Sentiment Score\", y = \"Frequency\") +\n  ggtitle(\"Distribution of Sentiment Scores of the Tweets\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n        axis.title = element_text(size = 12),\n        axis.text = element_text(size = 10),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        panel.border = element_blank(),\n        panel.background = element_blank()) +\n  easy_center_title()\n```\n\n::: {.cell-output-display}\n![](brand_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggsave(\"plot.png\", width = 8, height = 6, dpi = 300)  # Save the plot as an image file\n```\n:::\n\n\n\n### Wordcloud\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(RColorBrewer)\n\n# Create a text corpus\ntext_corpus <- Corpus(VectorSource(cleanText))\ntext_corpus <- tm_map(text_corpus, content_transformer(tolower))\ntext_corpus <- tm_map(text_corpus, removeWords, stopwords(\"english\"))\ntext_corpus <- tm_map(text_corpus, removeWords, c(\"global\", \"globalwarming\"))\n\n# Create a term-document matrix\ntdm <- TermDocumentMatrix(text_corpus)\ntdm <- as.matrix(tdm)\ntdm <- sort(rowSums(tdm), decreasing = TRUE)\ntdm <- data.frame(word = names(tdm), freq = tdm)\n\n\nset.seed(123)\n\nwordcloud(text_corpus, min.freq = 1, max.words = 100, scale = c(2.2,1),\n          colors=brewer.pal(8, \"Dark2\"), random.color = T, random.order = F)\n```\n\n::: {.cell-output-display}\n![](brand_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n### Word Frequency plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(tdm[1:20,], aes(x = reorder(word, freq), y = freq, fill = freq)) +\n  geom_bar(stat = \"identity\") +\n  xlab(\"Terms\") +\n  ylab(\"Count\") +\n  coord_flip() +\n  theme(axis.text = element_text(size = 7)) +\n  ggtitle(\"Most Common Word Frequency Plot\") +\n  easy_center_title() +\n  theme_minimal() +\n  scale_fill_gradient(low = \"#E5F5E0\", high = \"#31A354\")\n```\n\n::: {.cell-output-display}\n![](brand_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n## Network Analysis\n\n### Bigram analysis and Network definition\n\nBigram counts pairwise occurrences of words which appear together in the text.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#bigram\nbi.gram.words <- tweets.df %>% \n  unnest_tokens(\n    input = text, \n    output = bigram, \n    token = 'ngrams', \n    n = 2\n  ) %>% \n  filter(! is.na(bigram))\n\nbi.gram.words %>% \n  select(bigram) %>% \n  head(10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              bigram\n1         plus youve\n2        youve added\n3  added commercials\n4     commercials to\n5             to the\n6     the experience\n7   experience tacky\n8            i didnt\n9        didnt today\n10        today must\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nextra.stop.words <- c('https')\nstopwords.df <- tibble(\n  word = c(stopwords(kind = 'es'),\n           stopwords(kind = 'en'),\n           extra.stop.words)\n)\n```\n:::\n\n\nNext, we filter for stop words and remove white spaces.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbi.gram.words %<>% \n  separate(col = bigram, into = c('word1', 'word2'), sep = ' ') %>% \n  filter(! word1 %in% stopwords.df$word) %>% \n  filter(! word2 %in% stopwords.df$word) %>% \n  filter(! is.na(word1)) %>% \n  filter(! is.na(word2)) \n```\n:::\n\n\nFinally, we group and count by bigram.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbi.gram.count <- bi.gram.words %>% \n  dplyr::count(word1, word2, sort = TRUE) %>% \n  dplyr::rename(weight = n)\n\nbi.gram.count %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      word1     word2 weight\n1  customer   service    526\n2 cancelled flightled    451\n3      late    flight    232\n4 cancelled  flighted    202\n5   booking  problems    142\n6      late   flightr    142\n```\n:::\n:::\n\n\nLet us plot the distribution of the weightvalues:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Note that it is very skewed, for visualization purposes it might be a good idea to perform a transformation, eg log transform:\n\nbi.gram.count %>% \n  mutate(weight = log(weight + 1)) %>% \n  ggplot(mapping = aes(x = weight)) +\n  theme_light() +\n  geom_histogram(fill = \"#2171b5\") +\n  labs(title = \"Bigram log-Weight Distribution\")+\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](brand_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n### Network visualization\n\n\n::: {.cell}\n\n```{.r .cell-code}\nthreshold <- 50\n\n# For visualization purposes we scale by a global factor. \nScaleWeight <- function(x, lambda) {\n  x / lambda\n}\n\nnetwork <-  bi.gram.count %>%\n  filter(weight > threshold) %>%\n  mutate(weight = ScaleWeight(x = weight, lambda = 2E3)) %>% \n  graph_from_data_frame(directed = FALSE)\n\nplot(\n  network, \n  vertex.size = 1,\n  vertex.label.color = 'black', \n  vertex.label.cex = 0.7, \n  vertex.label.dist = 1,\n  edge.color = 'gray', \n  main = 'Bigram Count Network', \n  sub = glue('Weight Threshold: {threshold}'), \n  alpha = 50\n)\n```\n\n::: {.cell-output-display}\n![](brand_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\nWe can go a step further and make our visualization more dynamic using the networkD3 library.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nthreshold <- 50\n\nnetwork <-  bi.gram.count %>%\n  filter(weight > threshold) %>%\n  graph_from_data_frame(directed = FALSE)\n\n# Store the degree.\nV(network)$degree <- strength(graph = network)\n# Compute the weight shares.\nE(network)$width <- E(network)$weight/max(E(network)$weight)\n\n# Create networkD3 object.\nnetwork.D3 <- igraph_to_networkD3(g = network)\n# Define node size.\nnetwork.D3$nodes %<>% mutate(Degree = (1E-2)*V(network)$degree)\n# Define color group\nnetwork.D3$nodes %<>% mutate(Group = 1)\n# Define edges width. \nnetwork.D3$links$Width <- 10*E(network)$width\n\nforceNetwork(\n  Links = network.D3$links, \n  Nodes = network.D3$nodes, \n  Source = 'source', \n  Target = 'target',\n  NodeID = 'name',\n  Group = 'Group', \n  opacity = 0.9,\n  Value = 'Width',\n  Nodesize = 'Degree', \n  # We input a JavaScript function.\n  linkWidth = JS(\"function(d) { return Math.sqrt(d.value); }\"), \n  fontSize = 12,\n  zoom = TRUE, \n  opacityNoHover = 1\n)\n```\n\n::: {.cell-output-display}\n```{=html}\n<div class=\"forceNetwork html-widget html-fill-item-overflow-hidden html-fill-item\" id=\"htmlwidget-0db292064bd8899b8621\" style=\"width:100%;height:464px;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-0db292064bd8899b8621\">{\"x\":{\"links\":{\"source\":[7,15,5,6,12,5,16,3,1,2,1,1,1,2,4,8,11,13,9,3,3,0],\"target\":[23,30,28,22,27,10,31,5,5,5,5,19,18,21,11,24,26,29,25,20,14,17],\"value\":[10,8.57414448669202,4.4106463878327,3.84030418250951,2.69961977186312,2.69961977186312,2.56653992395437,2.09125475285171,1.69201520912548,1.61596958174905,1.38783269961977,1.34980988593156,1.31178707224335,1.29277566539924,1.12167300380228,1.10266159695817,1.06463878326996,1.00760456273764,1.00760456273764,1.00760456273764,0.988593155893536,0.96958174904943],\"colour\":[\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\"]},\"nodes\":{\"name\":[\"customer\",\"cancelled\",\"late\",\"booking\",\"cant\",\"flight\",\"call\",\"gate\",\"please\",\"right\",\"connecting\",\"get\",\"first\",\"looks\",\"reflight\",\"us\",\"rtour\",\"service\",\"flightled\",\"flighted\",\"problems\",\"flightr\",\"back\",\"agent\",\"help\",\"now\",\"home\",\"class\",\"attendant\",\"like\",\"airways\",\"fleets\"],\"group\":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\"nodesize\":[5.26,8.59,3.74,2.84,1.1,6.39,0.85,0.73,0.69,0.68,0.59,1.68,0.56,0.53,0.53,0.52,0.51,5.26,4.51,2.02,1.42,1.42,0.85,0.73,0.69,0.68,0.58,0.56,0.53,0.53,0.52,0.51]},\"options\":{\"NodeID\":\"name\",\"Group\":\"Group\",\"colourScale\":\"d3.scaleOrdinal(d3.schemeCategory20);\",\"fontSize\":12,\"fontFamily\":\"serif\",\"clickTextSize\":30,\"linkDistance\":50,\"linkWidth\":\"function(d) { return Math.sqrt(d.value); }\",\"charge\":-30,\"opacity\":0.9,\"zoom\":true,\"legend\":false,\"arrows\":false,\"nodesize\":true,\"radiusCalculation\":\" Math.sqrt(d.nodesize)+6\",\"bounded\":false,\"opacityNoHover\":1,\"clickAction\":null}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n:::\n:::\n\n\n### References:\n\nBing Liu, Minqing Hu and Junsheng Cheng. \"Opinion Observer: Analyzing and Comparing Opinions on the Web.\" Proceedings of the 14th International World Wide Web conference (WWW-2005), May 10-14, 2005, Chiba, Japan.\n",
    "supporting": [
      "brand_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/htmlwidgets-1.6.2/htmlwidgets.js\"></script>\r\n<script src=\"../../site_libs/plotly-binding-4.10.1/plotly.js\"></script>\r\n<script src=\"../../site_libs/typedarray-0.1/typedarray.min.js\"></script>\r\n<script src=\"../../site_libs/jquery-3.5.1/jquery.min.js\"></script>\r\n<link href=\"../../site_libs/crosstalk-1.2.0/css/crosstalk.min.css\" rel=\"stylesheet\" />\r\n<script src=\"../../site_libs/crosstalk-1.2.0/js/crosstalk.min.js\"></script>\r\n<link href=\"../../site_libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css\" rel=\"stylesheet\" />\r\n<script src=\"../../site_libs/plotly-main-2.11.1/plotly-latest.min.js\"></script>\r\n<script src=\"../../site_libs/d3-4.5.0/d3.min.js\"></script>\r\n<script src=\"../../site_libs/forceNetwork-binding-0.4/forceNetwork.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}